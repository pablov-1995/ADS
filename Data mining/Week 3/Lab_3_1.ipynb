{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sj7Eb4zxiVRo"
   },
   "source": [
    "# Data Mining: lab 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltT4HuB5igOk"
   },
   "source": [
    "#### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "32sbMN7JVyc9"
   },
   "outputs": [],
   "source": [
    "# Counter\n",
    "from collections import Counter\n",
    "\n",
    "# gensim\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "# json\n",
    "import json\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# pickle\n",
    "import pickle\n",
    "\n",
    "# pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# tqdm\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "# spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gu1s4He6iUi-"
   },
   "source": [
    "#### Correction of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_YswQDrAYXz6"
   },
   "outputs": [],
   "source": [
    "PATH_DF = 'english_cleaned_lyrics.csv'\n",
    "PATH_CORRECTION = 'indx2newdate.p'\n",
    "\n",
    "def load_dataset(data_path, path_correction):\n",
    "    df = pd.read_csv(data_path)\n",
    "    indx2newdate = pickle.load(open(PATH_CORRECTION, 'rb'))\n",
    "    df['year'] = df['index'].apply(lambda x: int(indx2newdate[x][0][:4]) if indx2newdate[x][0] != '' else 0)\n",
    "    return df[df.year > 1960][['song', 'year', 'artist', 'genre', 'lyrics']]\n",
    "    \n",
    "dataset = load_dataset(PATH_DF, PATH_CORRECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNdVPgu2jC7Z"
   },
   "source": [
    "### 1. Count how many songs of each genre are in the data set, and pick a genre that 1) you think is interesting to explore and 2) has over 5.000 songs. Make a subset of the data set only containing songs of that genre; this is the data set you work with for the rest of these exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9R1VBwAjRPH",
    "outputId": "810f4990-98eb-4cab-fca5-9a5161ec4215"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Folk           1373\n",
       "R&B            2338\n",
       "Other          2449\n",
       "Indie          2489\n",
       "Jazz           5068\n",
       "Electronic     5194\n",
       "Country       10545\n",
       "Hip-Hop       14878\n",
       "Metal         15671\n",
       "Pop           23295\n",
       "Rock          77556\n",
       "Name: song, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby(by=\"genre\").count()[\"song\"].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GWLots9jWim"
   },
   "source": [
    "I will choose to explore the lyrics of Hip Hop songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NIsBMlGgmCxE"
   },
   "outputs": [],
   "source": [
    "hiphop = dataset[dataset.genre == \"Hip-Hop\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gw3XChjmE_y"
   },
   "source": [
    "### 2. Inspect the number of songs for each year, either using a data frame or using a visualization. Do you think you have enough songs for each year (at least more than fifty)? If not, filter out the years that do not contain enough songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWuHWeevZCan",
    "outputId": "64822838-568d-4146-f58b-783821be49d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1961, 1963, 1966, 1969, 1970, 1971, 1974, 1977, 1978, 1979, 1980,\n",
       "            1981, 1982, 1983, 1984, 1985, 1986, 1987],\n",
       "           dtype='int64', name='year')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = hiphop.groupby(by=\"year\").count()[\"song\"].apply(lambda v: v if v <= 50 else None).dropna().index\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWnxcTcilEKS",
    "outputId": "0c1b90ef-2e38-4961-91f3-027f2b8724a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14777"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = hiphop[~hiphop.year.isin(ids)].lyrics.values\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQiwFYqmk1Cg"
   },
   "source": [
    "After filtering out of the selection those years where there were less than 50 hiphop songs, there are 14777 songs remaining in the dataset, enough to perform the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ma2Es8rmTLl"
   },
   "source": [
    "### 3. Process the texts of your genre (and only your genre!) using Spacy. Extract the lemmatized tokens for each song, and remove stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op0cGEKQmsuA"
   },
   "source": [
    "I will use nlp.pipe to process the lyrics of the songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "2dbf797b710649e3860bdc8c249cf05a",
      "dc16b8d4d24d4dde92f851d816945267",
      "32338c21c2f3479d9fce9728c78372a8",
      "b21ed839884646d08f582fb9fa8cfc00",
      "de97e1a9f3064594ac1d516523cd2ee7",
      "952f00898691499ba79c3b82ca42732f",
      "ecd847c6e343480eb3b1c873e27504e5",
      "96aa39a145264062a9a7ce9e5c166f9d"
     ]
    },
    "id": "emte4UbnZQV5",
    "outputId": "a017a5b4-db3e-4601-d207-db4b93868415"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "processed_texts = [text \n",
    "                   for text in tqdm_notebook(\n",
    "                       nlp.pipe(\n",
    "                           data, n_process=-1, disable=[\"ner\", \"parser\"]\n",
    "                           ), total=len(data)\n",
    "                   )\n",
    "                   ]\n",
    "lemma = [\n",
    "         [token.lemma_ for token in text if not token.is_punct and not token.is_stop] \n",
    "         for text in processed_texts\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5apjdbirmrJp"
   },
   "source": [
    "Since the step of processing texts takes a long time, I will save the lemmas as a json file so I don't have to do it again if I restart the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuwCGDw9mpLs"
   },
   "outputs": [],
   "source": [
    "with open('hiphop_lemma.json', 'w') as file:\n",
    "    json.dump(lemma, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3gMV9mzGoKcc"
   },
   "outputs": [],
   "source": [
    "with open('hiphop_lemma.json') as json_file:\n",
    "    lemma = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGwG48Kbob-4"
   },
   "source": [
    "### 4. Create a dictionary and filter out the words that occur less than three times, and all words that occur in over 85% of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TDBU2tVfocbm"
   },
   "outputs": [],
   "source": [
    "MIN_DF = 3 # minium document frequency\n",
    "MAX_DF = 0.85 # maximum document frequency\n",
    "dictionary = Dictionary(lemma) # get the vocabulary\n",
    "dictionary.filter_extremes(no_below=MIN_DF, no_above=MAX_DF)\n",
    "corpus = [dictionary.doc2bow(text) for text in lemma]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JE-heuwo2C9"
   },
   "source": [
    "### 5. Train a topic model with 50 topics and inspect the output, both using the ten most relevant words for each topics, and using pyLDAvis. Now also run a topic model with 20 topics, and one with 100 topics. Be sure to save the models using lda.save('folder_to_save') What number of topics does result in the “best” topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "R3DwWbnUo8-9"
   },
   "outputs": [],
   "source": [
    "PATH_TO_MALLET = '/home/pablo/Documents/github-repos/Mallet/bin/mallet'\n",
    "N_TOPICS = 50\n",
    "N_ITERATIONS = 1000\n",
    "\n",
    "lda = LdaMallet(PATH_TO_MALLET,\n",
    "                corpus=corpus,\n",
    "                id2word=dictionary,\n",
    "                num_topics=N_TOPICS,\n",
    "                iterations=N_ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.save('fifty_topics.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MALLET = '/home/pablo/Documents/github-repos/Mallet/bin/mallet'\n",
    "N_TOPICS = 20\n",
    "N_ITERATIONS = 1000\n",
    "\n",
    "lda = LdaMallet(PATH_TO_MALLET,\n",
    "                corpus=corpus,\n",
    "                id2word=dictionary,\n",
    "                num_topics=N_TOPICS,\n",
    "                iterations=N_ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.save('twenty_topics.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MALLET = '/home/pablo/Documents/github-repos/Mallet/bin/mallet'\n",
    "N_TOPICS = 100\n",
    "N_ITERATIONS = 1000\n",
    "\n",
    "lda = LdaMallet(PATH_TO_MALLET,\n",
    "                corpus=corpus,\n",
    "                id2word=dictionary,\n",
    "                num_topics=N_TOPICS,\n",
    "                iterations=N_ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.save('hundred_topics.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_twenty = LdaMallet.load('twenty_topics.model')\n",
    "lda_fifty = LdaMallet.load('fifty_topics.model')\n",
    "lda_hundred = LdaMallet.load('hundred_topics.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to decide which models performs best, I will use the coherence score of each of them. This index measures how coherent the topics are with the words of our dataset. The closest it is to 1, the better the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.3919732347888762\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_hundred, texts=lemma, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda_hundred = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda_hundred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.4025249677018343\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_fifty, texts=lemma, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda_fifty = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda_fifty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.41639203549255577\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_twenty, texts=lemma, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda_twenty = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda_twenty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the model with twenty topics seems to be the one that performs the best (as it has the highest coherence score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Make a change in the preprocessing stage and run the topic model again. This could be: not removing stop words, only selecting nouns (or only nouns, adjectives and verbs – something I do quite often when topic modeling), not using lemmas but tokens, etc. Inspect the output.  Name one benefit and one downside of the change you selected on the preprocessing stage for finding useful topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to select the tokens instead of the lemmas, and to also include stopwords in the selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hiphop_tokens.json') as json_file:\n",
    "    tokens = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_tokens = Dictionary(tokens) # get the vocabulary\n",
    "dictionary_tokens.filter_extremes(no_below=MIN_DF, no_above=MAX_DF)\n",
    "corpus_tokens = [dictionary.doc2bow(text) for text in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMallet(PATH_TO_MALLET,\n",
    "                corpus=corpus_tokens,\n",
    "                id2word=dictionary_tokens,\n",
    "                num_topics=N_TOPICS,\n",
    "                iterations=N_ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.save('twenty_topics_tokens.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.536634905151316\n"
     ]
    }
   ],
   "source": [
    "coherence_model_tokens = CoherenceModel(model=lda, texts=tokens, dictionary=dictionary_tokens, coherence='c_v')\n",
    "coherence_tokens = coherence_model_tokens.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_tokens)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Lab-3-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ADS",
   "language": "python",
   "name": "ads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2dbf797b710649e3860bdc8c249cf05a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_32338c21c2f3479d9fce9728c78372a8",
       "IPY_MODEL_b21ed839884646d08f582fb9fa8cfc00"
      ],
      "layout": "IPY_MODEL_dc16b8d4d24d4dde92f851d816945267"
     }
    },
    "32338c21c2f3479d9fce9728c78372a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_952f00898691499ba79c3b82ca42732f",
      "max": 15569,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de97e1a9f3064594ac1d516523cd2ee7",
      "value": 15569
     }
    },
    "952f00898691499ba79c3b82ca42732f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96aa39a145264062a9a7ce9e5c166f9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b21ed839884646d08f582fb9fa8cfc00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96aa39a145264062a9a7ce9e5c166f9d",
      "placeholder": "​",
      "style": "IPY_MODEL_ecd847c6e343480eb3b1c873e27504e5",
      "value": " 15569/15569 [02:44&lt;00:00, 94.87it/s]"
     }
    },
    "dc16b8d4d24d4dde92f851d816945267": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de97e1a9f3064594ac1d516523cd2ee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ecd847c6e343480eb3b1c873e27504e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
